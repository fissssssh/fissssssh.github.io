<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>K8s on fissssssh</title><link>https://blog.fissssssh.com/tags/k8s/</link><description>Recent content in K8s on fissssssh</description><generator>Hugo -- gohugo.io</generator><lastBuildDate>Mon, 24 Apr 2023 16:22:05 +0800</lastBuildDate><atom:link href="https://blog.fissssssh.com/tags/k8s/index.xml" rel="self" type="application/rss+xml"/><item><title>如何使用Logstash将日志写入阿里云SLS服务</title><link>https://blog.fissssssh.com/posts/how-to-write-logs-to-aliyun-sls-using-logstash/</link><pubDate>Mon, 24 Apr 2023 16:22:05 +0800</pubDate><guid>https://blog.fissssssh.com/posts/how-to-write-logs-to-aliyun-sls-using-logstash/</guid><description>当你的应用程序越来越大，日志的管理变得越来越困难。而将日志存储在云服务上是现代化应用中的一个不可忽视的方面。在云服务中，阿里云 SLS 是一个非常好的选择，它可以帮助你收集、存储和查询应用程序日志。但是，如何将应用程序的日志发送到阿里云 SLS 服务呢？今天，我们将使用 Logstash，一个流行的开源工具，来将我们的日志发送到阿里云 SLS 服务中。
简介 阿里云 SLS 服务 阿里云 SLS（云监控日志服务）是一种高可靠、高扩展性的日志服务，主要用于收集和实时处理来自服务器、应用程序和云产品的日志数据。 SLS 提供了实时的查询、统计和报警等功能，有助于用户更轻松地管理日志。
SLS 支持大规模的日志数据处理，可以通过多种方式上传日志数据，例如 SDK、API、SLS Agent、Logstash 等，使用 SLS 可以快速查询、分析和可视化日志数据，帮助用户更好地理解自己的应用环境。
Logstash Logstash 则是一款通用的日志收集工具，可以将来自不同来源的日志数据进行收集、处理、转换和传输。Logstash 可以与各种插件配合使用，从而实现更多功能。例如，用户可以使用 Logstash 的 input 插件来收集来自多个来源的日志数据，使用 filter 插件来解析、过滤和重构这些数据，最后使用 output 插件将处理后的数据发送到各种目的地，如 Elasticsearch、Kibana 等。
准备工作 创建阿里云 SLS 服务实例 略
安装 Logstash 本文使用的 Logstash 版本为 8.7.0（截至本文发布最新版）
阿里云官方文档介绍了如何安装 Logstash，但如果要在 K8s 中运行则需要进行一些其他操作：
构建带有 logstash-output-logservice 插件的 Logstash 镜像 编写 Logstash 配置文件 部署至 K8s 构建镜像 通过 Dockerfile 来构建包含 logstash-output-logservice 插件的 Logstash 镜像，文件内容如下：</description></item><item><title>从 K8s 的 Pod 中拷贝大文件</title><link>https://blog.fissssssh.com/posts/copy-large-file-from-k8s-pod/</link><pubDate>Fri, 24 Mar 2023 12:48:02 +0800</pubDate><guid>https://blog.fissssssh.com/posts/copy-large-file-from-k8s-pod/</guid><description>从 K8s 的容器中拷贝文件可以使用kubectl cp命令，但是对于较大的文件（100M 以上）可能就不是很好使了，拷贝过程经常会出现EOF错误
对于较大的文件，我是这样操作的：
压缩
通过压缩可以减小大文件的体积
tar -czvf largefile.tar.gz largefile 此操作也可以用于打包整个文件夹，以便达到拷贝文件夹的目的
分片
对于体积较大的文件，即使压缩后仍然有好几百 M，这时使用kubectl cp也不一定能够拷贝下来，所以需要对其分割
split -b 50M -d largefile.tar.gz largefile.tar.gz 此操作会将largefile.tar.gz按照 50M/每个文件的大小分割为多个文件，-d选项则是使用数字来作为后缀（默认是英文字母）
例如：largefile.tar.gz有 220M，则分割后会变为
largefile.tar.gz00 # 50M largefile.tar.gz01 # 50M largefile.tar.gz02 # 50M largefile.tar.gz03 # 50M largefile.tar.gz04 # 20M 拷贝
使用kubectl cp命令拷贝分割后的文件
kubectl cp &amp;lt;pod-name&amp;gt;:largefile.tar.gz00 largefile.tar.gz00 kubectl cp &amp;lt;pod-name&amp;gt;:largefile.tar.gz00 largefile.tar.gz01 kubectl cp &amp;lt;pod-name&amp;gt;:largefile.tar.gz00 largefile.tar.gz02 kubectl cp &amp;lt;pod-name&amp;gt;:largefile.tar.gz00 largefile.tar.gz03 kubectl cp &amp;lt;pod-name&amp;gt;:largefile.tar.gz00 largefile.tar.gz04 对于多个容器的 Pod,可以使用-c选项指定具体的容器
合并 使用cat命令合并多个文件
cat largefile.</description></item></channel></rss>